# driver_node.py
# PyTorch DAVE-2 ê¸°ë°˜ ììœ¨ì£¼í–‰ ROS 2 ë…¸ë“œ (W640 + Turn_Mode ì…ë ¥)

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CompressedImage 
from geometry_msgs.msg import Twist 
from std_msgs.msg import Bool # <--- Turn Mode ë°ì´í„°ë¥¼ ìœ„í•œ Bool ë©”ì‹œì§€ ì„í¬íŠ¸
import message_filters # <--- ë™ê¸°í™”ë¥¼ ìœ„í•œ message_filters ì„í¬íŠ¸
from cv_bridge import CvBridge # <--- ì´ë¯¸ì§€ ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ CvBridge ì„í¬íŠ¸
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
import os

# --- 1. ì „ì—­ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° (í›ˆë ¨ íŒŒì¼ê³¼ ë™ì¼) ---

IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 320, 640, 3 

# ğŸš¨ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì €ì¥ëœ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.
FINAL_MODEL_SAVE_PATH = 'best_model.pth' 

# --- 2. ëª¨ë¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ (í›ˆë ¨ íŒŒì¼ê³¼ ë™ì¼) ---

def preprocess_image(img):
    """ 
    [W640 ì ìš©] ì´ë¯¸ì§€ì˜ ì•„ë˜ìª½ ì ˆë°˜ (160:320)ê³¼ ì „ì²´ ë„“ì´ (0:640)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    img_resized = cv2.resize(img, (640, 320))
    # ROI: ì•„ë˜ìª½ ì ˆë°˜ 160:320
    img_roi = img_resized[160:320, 0:640] 
    img_roi = cv2.cvtColor(img_roi, cv2.COLOR_BGR2RGB)
    # ìµœì¢… DAVE-2 ì…ë ¥ í¬ê¸° (ì—¬ê¸°ì„œëŠ” 320x640)ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    img_final = cv2.resize(img_roi, (IMAGE_WIDTH, IMAGE_HEIGHT)) 
    return img_final

# --- 3. PyTorch ëª¨ë¸ ì •ì˜ (í›ˆë ¨ ì½”ë“œì™€ ì™„ë²½íˆ ì¼ì¹˜) ---

class ImprovedDave2Model(nn.Module):
    """
    ê°œì„ ëœ DAVE-2 PyTorch ëª¨ë¸ (W640 + Turn_Mode ì…ë ¥)
    """
    # ğŸš¨ turn_modeì˜ ì˜í–¥ë ¥ì„ ê°•í™”í•˜ê¸° ìœ„í•œ ìŠ¤ì¼€ì¼ë§ íŒ©í„° (í›ˆë ¨ ì‹œì™€ ë™ì¼í•´ì•¼ í•¨!)
    # í›ˆë ¨ ì‹œ 12800.0ì„ ì‚¬ìš©í–ˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
    TURN_MODE_SCALE_FACTOR = 12800.0 
    
    def __init__(self):
        super(ImprovedDave2Model, self).__init__()
        
        CNN_OUTPUT_SIZE = 12800 
        SCALAR_INPUT_SIZE = 1 
        TOTAL_FC_INPUT_SIZE = CNN_OUTPUT_SIZE + SCALAR_INPUT_SIZE 
        
        # CNN ë ˆì´ì–´ ì •ì˜ (í›ˆë ¨ ì‹œì™€ ë™ì¼)
        self.conv1 = nn.Conv2d(IMAGE_CHANNELS, 24, kernel_size=5, stride=2, padding=2) 
        self.bn1 = nn.BatchNorm2d(24)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop1 = nn.Dropout(0.1)
        
        self.conv2 = nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=2)
        self.bn2 = nn.BatchNorm2d(36)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop2 = nn.Dropout(0.1)
        
        self.conv3 = nn.Conv2d(36, 48, kernel_size=5, stride=2, padding=2)
        self.bn3 = nn.BatchNorm2d(48)
        self.drop3 = nn.Dropout(0.2)
        
        self.conv4 = nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm2d(64)
        self.drop4 = nn.Dropout(0.2)
        
        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn5 = nn.BatchNorm2d(64)
        self.drop5 = nn.Dropout(0.3)
        
        self.flatten = nn.Flatten()
        
        self.fc1 = nn.Linear(TOTAL_FC_INPUT_SIZE, 100) 
        self.bn_fc1 = nn.BatchNorm1d(100)
        self.drop_fc1 = nn.Dropout(0.4)
        
        self.fc2 = nn.Linear(100, 50)
        self.bn_fc2 = nn.BatchNorm1d(50)
        self.drop_fc2 = nn.Dropout(0.3)
        
        self.fc3 = nn.Linear(50, 10)
        self.drop_fc3 = nn.Dropout(0.2)
        
        self.output = nn.Linear(10, 1) # ì¶œë ¥ 1ê°œ: [omega_z]

    def forward(self, x_img, x_scalar):
        # 1. CNN ì²˜ë¦¬
        x = self.drop1(self.pool1(F.relu(self.bn1(self.conv1(x_img)))))
        x = self.drop2(self.pool2(F.relu(self.bn2(self.conv2(x)))))
        x = self.drop3(F.relu(self.bn3(self.conv3(x))))
        x = self.drop4(F.relu(self.bn4(self.conv4(x))))
        x = self.drop5(F.relu(self.bn5(self.conv5(x))))
        
        x = self.flatten(x)
        
        # ğŸš¨ 2. CNN ì¶œë ¥ê³¼ ìŠ¤ì¹¼ë¼ ì…ë ¥ ê²°í•© (ìŠ¤ì¼€ì¼ë§ ì ìš©)
        scaled_scalar = x_scalar * self.TURN_MODE_SCALE_FACTOR 
        x = torch.cat((x, scaled_scalar), dim=1)
        
        # 3. FC ì²˜ë¦¬
        x = self.drop_fc1(F.relu(self.bn_fc1(self.fc1(x))))
        x = self.drop_fc2(F.relu(self.bn_fc2(self.fc2(x))))
        x = self.drop_fc3(F.relu(self.fc3(x)))
        
        x = self.output(x)
        return x

# --- 4. ROS 2 ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜ (ìˆ˜ì •ë¨: ë™ê¸°í™” ë° ë“€ì–¼ êµ¬ë…) ---

class DriverNode(Node):
    def __init__(self):
        super().__init__('driver_node')
        
        self.bridge = CvBridge() # CvBridge ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        
        # 1. ì¥ì¹˜ ì„¤ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"âœ… PyTorch ì‹¤í–‰ ì¥ì¹˜: {self.device}")
        
        # 2. PyTorch ëª¨ë¸ ë¡œë“œ
        self.model = ImprovedDave2Model()
        self.load_model()
        self.model.to(self.device)
        self.model.eval() 

        # 3. ROS 2 êµ¬ë… ì„¤ì • ë° ë™ê¸°í™” (ApproximateTimeSynchronizer ì‚¬ìš©)
        SYNC_SLOP: float = 0.05 
        
        # ğŸš¨ êµ¬ë…ì ì •ì˜
        self.image_sub = message_filters.Subscriber(self, CompressedImage, '/camera/color/image_raw/compressed')
        self.turn_mode_sub = message_filters.Subscriber(self, Bool, '/turn_mode') 
        
        self.ts = message_filters.ApproximateTimeSynchronizer(
            [self.image_sub, self.turn_mode_sub], # ğŸš¨ ë‘ ê°œì˜ êµ¬ë…ì ë¦¬ìŠ¤íŠ¸
            queue_size=10, 
            slop=SYNC_SLOP,
            allow_headerless=True 
        )
        
        # ğŸš¨ ë™ê¸°í™” ì½œë°± ë“±ë¡
        self.ts.registerCallback(self.synchronized_callback)
        self.get_logger().info("âœ… ì´ë¯¸ì§€/Turn Mode í† í”½ ë™ê¸°í™” êµ¬ë… ì‹œì‘")
        
        # 5. ROS 2 ë°œí–‰ ì„¤ì • (Twist ë©”ì‹œì§€)
        self.publisher_ = self.create_publisher(
            Twist,
            '/cmd_vel', 
            10
        )
        self.get_logger().info("âœ… ì œì–´ í† í”½ ë°œí–‰ ì‹œì‘: /cmd_vel")

    def load_model(self):
        """í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if not os.path.exists(FINAL_MODEL_SAVE_PATH):
            self.get_logger().error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {FINAL_MODEL_SAVE_PATH}")
            self.get_logger().error("âš ï¸ ì„ì˜ì˜ (í›ˆë ¨ë˜ì§€ ì•Šì€) ëª¨ë¸ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            return

        try:
            self.model.load_state_dict(
                torch.load(FINAL_MODEL_SAVE_PATH, map_location=self.device)
            )
            self.get_logger().info(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {FINAL_MODEL_SAVE_PATH}")
        except Exception as e:
            self.get_logger().error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    def synchronized_callback(self, image_msg: CompressedImage, turn_mode_msg: Bool):
        """ì´ë¯¸ì§€ ë©”ì‹œì§€ì™€ Turn Mode ë©”ì‹œì§€ê°€ ë™ê¸°í™”ë˜ì–´ ìˆ˜ì‹ ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤."""
        try:
            # 1. CompressedImage -> OpenCV BGR Image (CvBridge ì‚¬ìš©)
            np_arr = np.frombuffer(image_msg.data, np.uint8)
            cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            if cv_image is None:
                self.get_logger().error("âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨.")
                return

        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë””ì½”ë”©/ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return
        
        # 2. Turn Mode ê°’ ì¶”ì¶œ ë° ë³€í™˜ (Bool -> float)
        # Bool ë©”ì‹œì§€ì˜ data í•„ë“œëŠ” True/Falseë¥¼ ê°€ì§€ë©°, ì´ë¥¼ 1.0 ë˜ëŠ” 0.0ìœ¼ë¡œ ë³€í™˜
        current_turn_mode_value = 1.0 if turn_mode_msg.data else 0.0

        # 3. PyTorch ì¶”ë¡  ë° ì œì–´ ê°’ íšë“
        omega_z = self.infer_control(cv_image, current_turn_mode_value)

        # 4. ì œì–´ ëª…ë ¹(Twist ë©”ì‹œì§€) ìƒì„± ë° ë°œí–‰
        twist_msg = Twist()
        twist_msg.linear.x = 0.3 # ê³ ì • ì„ ì†ë„
        twist_msg.angular.z = float(omega_z)

        self.publisher_.publish(twist_msg)
        self.get_logger().info(f'ğŸ“¢ ë°œí–‰: V_x={0.3:.4f}, Omega_z={omega_z:.4f} (Turn Mode: {current_turn_mode_value})')

    def infer_control(self, cv_image, current_turn_mode_value: float):
        """ OpenCV ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. """
        
        # 1. ì „ì²˜ë¦¬ (W640 ROI ë° ìµœì¢… í¬ê¸°ë¡œ ì¡°ì •)
        preprocessed_img = preprocess_image(cv_image) 

        # 2. PyTorch Tensorë¡œ ë³€í™˜ ë° ì •ê·œí™”
        img_tensor = (preprocessed_img / 255.0) - 0.5
        img_tensor = np.transpose(img_tensor, (2, 0, 1)) 
        
        img_tensor = torch.tensor(img_tensor, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # ğŸš¨ ìŠ¤ì¹¼ë¼ ì…ë ¥ í…ì„œ ì¤€ë¹„: [current_turn_mode_value]
        # Bool ê°’ì´ True(1.0) ë˜ëŠ” False(0.0)ë¡œ ë³€í™˜ëœ ê°’ì´ ì‚¬ìš©ë¨
        scalar_input_tensor = torch.tensor([current_turn_mode_value], dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # 3. ì¶”ë¡  (Inference)
        with torch.no_grad():
            # ğŸš¨ ì´ë¯¸ì§€ì™€ ìŠ¤ì¹¼ë¼ ì…ë ¥ì„ í•¨ê»˜ ëª¨ë¸ì— ì „ë‹¬
            outputs = self.model(img_tensor, scalar_input_tensor)
            prediction = outputs.cpu().numpy()[0] 

        # 4. ê²°ê³¼ ë°˜í™˜
        angular_velocity_z = prediction[0]

        # ğŸš¨ ê°ì†ë„ í´ë¦¬í•‘ (í•„ìš”ì‹œ í™œì„±í™”)
        # angular_velocity_z = np.clip(angular_velocity_z, -1.0, 1.0)

        return angular_velocity_z


def main(args=None):
    rclpy.init(args=args)
    driver_node = DriverNode()
    
    try:
        rclpy.spin(driver_node)
    except KeyboardInterrupt:
        pass
        
    driver_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()